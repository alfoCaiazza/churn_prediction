{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf0ce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 15:19:54.802679: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-28 15:19:54.891708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-28 15:19:56.851576: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/tmp/ipykernel_12086/1167736315.py:15: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from dagshub import dagshub_logger\n",
    "import json\n",
    "import os\n",
    "import keras\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from kerastuner.tuners import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed2c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as alfoCaiazza\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as alfoCaiazza\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"alfoCaiazza/churn_prediction\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"alfoCaiazza/churn_prediction\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository alfoCaiazza/churn_prediction initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository alfoCaiazza/churn_prediction initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dagshub and MLflow setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/alfoCaiazza/churn_prediction.mlflow\")\n",
    "dagshub.init(repo_owner=\"alfoCaiazza\", repo_name=\"churn_prediction\", mlflow=True)\n",
    "dagshub_logger = dagshub_logger(metrics_path=\"metrics\", hparams_path=\"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c348c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Setting up GPU usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU: {gpu}\")\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb31fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrizing the SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_SVM(hp):\n",
    "    kernel_name = hp.Choice('kernel', values=['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    C = hp.float('C', min_value=1e-3, max_value=1e3, sampling='log')\n",
    "\n",
    "    # Gamma value only for non-linear kernels\n",
    "    gamma = 'scale'\n",
    "    if kernel_name in ['poly', 'rbf', 'sigmoid']:\n",
    "        gamma = hp.Choice('gamma', values=['scale', 'auto'])\n",
    "    \n",
    "    # Degree value only for polynomial kernel\n",
    "    degree = 3\n",
    "    if kernel_name == 'poly':\n",
    "        degree = hp.Int('degree', min_value=2, max_value=6, step=1)\n",
    "\n",
    "    svm = SVC(\n",
    "        kernel=kernel_name, C=C, gamma=gamma, degree=degree\n",
    "    )\n",
    "    \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6520bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Callbacks\n",
    "base_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Custom Callback for MLflow logging\n",
    "class MLflowCallback(Callback):\n",
    "    def __init__(self, trial_id, trial_hyperparameters):\n",
    "        super().__init__()\n",
    "        self.trial_id = trial_id\n",
    "        self.trial_hyperparameters = trial_hyperparameters\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.run = mlflow.start_run(run_name = f\"trial_{self.trial_id}\", nested=True)\n",
    "\n",
    "        mlflow.log_param('trial_id', self.trial_id)\n",
    "        for param_name, param_value in self.trial_hyperparameters.values.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            for metric_name, value in logs.items():\n",
    "                mlflow.log_metric(metric_name, value, step=epoch)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.run:\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sublassing BayesianOptimization to include MLflow tracking callback\n",
    "class MyTuner(BayesianOptimization):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        callbacks = base_callbacks + [MLflowCallback(trial.hyperparameters, trial.trial_id)]\n",
    "        kwargs['callbacks'] = callbacks\n",
    "\n",
    "        return super().run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model training phase\n",
    "TUNER_DIR = \"src/tuning\" \n",
    "with mlflow.start_run(run_name=\"Main_run\"):\n",
    "    mlflow.set_tag(\"stage\", \"hyperparameter_tuning\")\n",
    "    mlflow.set_tag(\"model\", \"parametrized_SVC\")\n",
    "\n",
    "    tuner = MyTuner(\n",
    "        build_SVM,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=20,\n",
    "        executions_per_trial=1,\n",
    "        directory=TUNER_DIR,\n",
    "        project_name='svm_parametrized'\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "\n",
    "    )\n",
    "\n",
    "    # TO DO \n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "template_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
